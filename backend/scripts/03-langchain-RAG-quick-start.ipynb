{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import dotenv\n",
    "\n",
    "# https://www.promptingguide.ai/zh/techniques/rag\n",
    "# https://python.langchain.com/docs/use_cases/question_answering/quickstart\n",
    "# Get the API key from the user 'input' \n",
    "# import getpass\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "# dot env ref:\n",
    "# https://stackoverflow.com/questions/40216311/reading-in-environment-variables-from-an-environment-file\n",
    "\n",
    "dotenv.load_dotenv(\"./.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000020A088D8490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020A088D9D80>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Models: \n",
    "# https://platform.openai.com/docs/models/gpt-3-5-turbo\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Sequence, Callable\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ExMongodbLoader(BaseLoader):\n",
    "    \"\"\"Load MongoDB documents.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        connection_string: str,\n",
    "        db_name: str,\n",
    "        collection_name: str,\n",
    "        *,\n",
    "        filter_criteria: Optional[Dict] = None,\n",
    "        field_names: Optional[Sequence[str]] = None,\n",
    "        doc_transformer: Callable = str,\n",
    "    ) -> None:\n",
    "        try:\n",
    "            from motor.motor_asyncio import AsyncIOMotorClient\n",
    "        except ImportError as e:\n",
    "            raise ImportError(\n",
    "                \"Cannot import from motor, please install with `pip install motor`.\"\n",
    "            ) from e\n",
    "        if not connection_string:\n",
    "            raise ValueError(\"connection_string must be provided.\")\n",
    "\n",
    "        if not db_name:\n",
    "            raise ValueError(\"db_name must be provided.\")\n",
    "\n",
    "        if not collection_name:\n",
    "            raise ValueError(\"collection_name must be provided.\")\n",
    "\n",
    "        self.client = AsyncIOMotorClient(connection_string)\n",
    "        self.db_name = db_name\n",
    "        self.collection_name = collection_name\n",
    "        self.filter_criteria = filter_criteria or {}\n",
    "        self.field_names = field_names or []\n",
    "        self.doc_transformer = doc_transformer\n",
    "\n",
    "        self.db = self.client.get_database(db_name)\n",
    "        self.collection = self.db.get_collection(collection_name)\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load data into Document objects.\n",
    "\n",
    "        Attention:\n",
    "\n",
    "        This implementation starts an asyncio event loop which\n",
    "        will only work if running in a sync env. In an async env, it should\n",
    "        fail since there is already an event loop running.\n",
    "\n",
    "        This code should be updated to kick off the event loop from a separate\n",
    "        thread if running within an async context.\n",
    "        \"\"\"\n",
    "        return asyncio.run(self.aload())\n",
    "\n",
    "    async def aload(self) -> List[Document]:\n",
    "        \"\"\"Load data into Document objects.\"\"\"\n",
    "        result = []\n",
    "        total_docs = await self.collection.count_documents(self.filter_criteria)\n",
    "\n",
    "        # Construct the projection dictionary if field_names are specified\n",
    "        projection = (\n",
    "            {field: 1 for field in self.field_names} if self.field_names else None\n",
    "        )\n",
    "\n",
    "        async for doc in self.collection.find(self.filter_criteria, projection):\n",
    "            metadata = {\n",
    "                \"database\": self.db_name,\n",
    "                \"collection\": self.collection_name,\n",
    "            }\n",
    "\n",
    "            # Extract text content from filtered fields or use the entire document\n",
    "            text = self.doc_transformer(doc)\n",
    "\n",
    "            result.append(Document(page_content=text, metadata=metadata))\n",
    "\n",
    "        if len(result) != total_docs:\n",
    "            logger.warning(\n",
    "                f\"Only partial collection of documents returned. \"\n",
    "                f\"Loaded {len(result)} docs, expected {total_docs}.\"\n",
    "            )\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# document loaders\n",
    "# https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "# https://python.langchain.com/docs/integrations/document_loaders/mongodb\n",
    "\n",
    "# add this import for running in jupyter notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# IT IS TOO WEAK:\n",
    "# from langchain_community.document_loaders.mongodb import MongodbLoader\n",
    "\n",
    "def transform_detail_doc(doc: dict) -> str:\n",
    "    return f'名称：{doc.get(\"项目名称\", \"\")}; 简介：{doc.get(\"项目信息\", {}).get(\"项目简介\", \"\")}'\n",
    "\n",
    "\n",
    "loader = ExMongodbLoader(\n",
    "    connection_string=\"mongodb://localhost:27017/\",\n",
    "    db_name=\"final\",\n",
    "    collection_name=\"itemDetail\",\n",
    "    doc_transformer=transform_detail_doc,\n",
    "    field_names=\"项目信息 项目名称\".split(),\n",
    ")\n",
    "# KeyError: '项目信息.项目简介'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247965"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_and_abstracts = loader.load()\n",
    "\n",
    "len(title_and_abstracts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 250000 docs\n",
    "- 20 char/doc\n",
    "- 5 token/char\n",
    "- 0.002 rmb/k*token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 rmb\n"
     ]
    }
   ],
   "source": [
    "print(250000*20*5*0.002/1000, \"rmb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='名称：高校校园建筑能耗模拟及节能改造设计---以广东白云学院为例; 简介：', metadata={'database': 'final', 'collection': 'itemDetail'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 一个文档似乎有点太长了\n",
    "# 加入简介是否必要？\n",
    "# 直接切分也不太合适，会出现只有简介的部分，对大模型选题造成干扰\n",
    "\n",
    "title_and_abstracts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loader = ExMongodbLoader(\n",
    "    connection_string=\"mongodb://localhost:27017/\",\n",
    "    db_name=\"final\",\n",
    "    collection_name=\"itemDetail\",\n",
    "    field_names= [\"项目名称\"],\n",
    "    doc_transformer=lambda x:str(x.get(\"项目名称\", \"\"))\n",
    ")\n",
    "titles = loader.load()\n",
    "titles = titles[:32]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.96875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chars_cnt = 0\n",
    "\n",
    "for doc in titles:\n",
    "    text = doc.page_content\n",
    "    chars_cnt += len(text)\n",
    "\n",
    "print(chars_cnt/len(titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高校校园建筑能耗模拟及节能改造设计---以广东白云学院为例\n",
      "大学生对中西方传统节日价值取向的研究\n",
      "“语伞”雨伞共享平台设计\n",
      "互联网+大学城闲散物流资源跨界整合创新实践\n",
      "太阳跟随系统\n",
      "移动快充跨境电商创业\n",
      "静态平衡仪\n",
      "疏勒河流域水-能源-粮食纽带关系研究\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(x.page_content) for x in titles[:8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-10 19:39:18] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import QianfanEmbeddingsEndpoint\n",
    "\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "\n",
    "# https://python.langchain.com/docs/modules/data_connection/text_embedding/\n",
    "# https://python.langchain.com/docs/integrations/text_embedding/baidu_qianfan_endpoint/\n",
    "\n",
    "# https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/elasticsearch/\n",
    "\n",
    "\n",
    "\n",
    "embedding = QianfanEmbeddingsEndpoint(model=\"Embedding-V1\")\n",
    "\n",
    "res = embedding.embed_documents([\n",
    "    \"你好，世界！\", \n",
    "    \"Hello, world!\",\n",
    "    \"国内链接OpenAI不太方便，于是我使用百度公司的model。\",\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.02, -0.04, -0.03, 0.10, -0.03, -0.05, 0.01, -0.05, 0.03, 0.01, 0.04, -0.13, 0.08, -0.02, -0.07, -0.02, 0.00, -0.00, 0.03, 0.02, -0.01, -0.04, -0.05, -0.02, 0.03, 0.03, 0.08, 0.05, 0.02, -0.01, -0.00, 0.02, 0.03, -0.06, -0.02, 0.05, 0.04, 0.02, -0.08, 0.04, -0.01, 0.05, -0.00, 0.09, 0.03, -0.06, -0.04, -0.08, -0.08, -0.05, 0.00, 0.01, -0.02, 0.08, -0.01, -0.04, -0.11, -0.02, 0.07, -0.06, 0.01, 0.06, 0.08, -0.06, 0.06, 0.01, -0.00, -0.00, 0.07, 0.01, -0.02, -0.03, 0.06, 0.08, -0.06, 0.04, -0.03, 0.00, -0.00, -0.02, 0.06, -0.08, 0.09, -0.07, -0.08, -0.01, 0.02, 0.04, -0.02, -0.01, -0.01, -0.08, 0.02, -0.08, -0.08, -0.04, 0.02, -0.01, -0.01, -0.07, 0.07, 0.06, 0.07, 0.00, 0.08, -0.05, -0.07, -0.11, 0.01, 0.04, -0.02, 0.05, 0.02, -0.01, -0.05, 0.08, 0.07, -0.02, 0.02, -0.05, -0.07, 0.08, -0.02, 0.11, -0.05, 0.06, -0.12, -0.04, -0.05, 0.06, 0.01, 0.01, 0.07, -0.01, -0.03, 0.00, 0.03, -0.02, -0.04, 0.09, -0.10, -0.02, -0.02, 0.07, 0.05, 0.09, 0.05, -0.01, -0.03, 0.03, -0.03, 0.01, -0.02, 0.00, -0.08, 0.02, 0.01, -0.06, -0.02, 0.07, 0.00, 0.05, 0.12, -0.07, 0.07, -0.01, -0.05, 0.03, -0.00, 0.04, -0.03, 0.08, -0.01, -0.02, -0.02, 0.02, 0.04, 0.01, -0.06, -0.00, -0.02, -0.01, 0.07, 0.02, 0.04, -0.11, -0.09, 0.03, -0.02, -0.10, 0.02, 0.06, -0.05, 0.05, -0.00, -0.05, -0.02, -0.05, -0.03, 0.06, -0.01, -0.01, 0.03, -0.08, -0.06, -0.04, -0.01, 0.06, -0.02, -0.01, -0.03, 0.03, 0.06, -0.10, 0.01, 0.06, -0.00, -0.02, 0.12, 0.04, -0.01, -0.00, 0.09, -0.04, 0.10, 0.07, 0.03, 0.06, 0.02, 0.03, 0.02, 0.01, 0.05, 0.08, 0.05, 0.00, 0.00, -0.08, 0.03, 0.03, -0.08, -0.10, 0.01, -0.09, 0.01, -0.04, 0.02, 0.12, -0.06, 0.05, -0.08, -0.02, -0.07, -0.03, 0.03, -0.06, 0.00, 0.00, 0.00, -0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.40, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.01, -0.39, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, \n",
      "0.07, -0.02, -0.10, 0.09, -0.05, -0.14, 0.03, -0.02, -0.03, -0.02, -0.00, -0.09, 0.06, -0.00, -0.08, 0.01, 0.00, -0.01, -0.00, -0.04, 0.03, -0.05, 0.00, -0.04, 0.03, 0.01, 0.05, 0.08, 0.03, 0.01, 0.01, 0.07, 0.08, -0.08, -0.04, 0.06, -0.02, 0.00, -0.03, 0.09, 0.03, -0.00, 0.03, -0.02, 0.08, -0.12, -0.06, -0.02, -0.07, 0.03, 0.00, 0.04, 0.11, 0.07, -0.02, -0.01, -0.07, -0.03, 0.06, -0.05, -0.05, 0.04, 0.10, -0.05, 0.10, 0.06, -0.03, 0.02, 0.04, -0.01, 0.03, -0.06, 0.03, 0.03, -0.02, 0.08, -0.01, 0.02, 0.07, -0.08, 0.08, 0.01, 0.09, 0.02, -0.12, -0.04, 0.11, 0.01, -0.00, -0.03, 0.01, -0.08, 0.08, -0.01, -0.11, -0.07, -0.05, 0.03, 0.01, -0.11, 0.01, 0.08, -0.00, 0.00, 0.10, -0.06, -0.08, -0.08, 0.03, 0.01, -0.08, 0.05, -0.05, 0.01, 0.01, 0.04, 0.01, -0.02, 0.01, 0.01, -0.03, 0.02, -0.05, 0.07, -0.07, 0.05, -0.14, -0.00, 0.01, 0.06, 0.08, 0.05, -0.04, 0.04, 0.02, 0.05, -0.02, -0.06, -0.06, 0.08, -0.06, 0.08, 0.05, 0.00, -0.04, 0.02, 0.03, -0.02, -0.03, -0.04, -0.08, 0.06, -0.04, -0.04, -0.08, 0.00, 0.11, -0.11, -0.07, 0.04, 0.02, -0.03, 0.07, -0.05, 0.02, 0.01, -0.01, 0.04, 0.05, 0.05, -0.07, 0.06, 0.02, -0.07, 0.04, 0.03, 0.04, 0.04, 0.05, -0.02, -0.05, -0.04, 0.05, -0.08, 0.04, -0.01, -0.06, 0.09, 0.02, -0.10, 0.02, 0.07, -0.03, -0.01, 0.00, -0.01, -0.00, -0.05, -0.04, 0.04, -0.01, 0.01, -0.00, -0.07, 0.02, -0.03, -0.10, 0.01, -0.02, 0.01, -0.00, 0.02, -0.01, -0.08, 0.02, 0.10, 0.03, -0.04, 0.17, 0.03, -0.06, 0.01, 0.11, -0.07, 0.07, 0.04, -0.00, -0.02, -0.00, -0.07, -0.01, -0.03, 0.04, 0.11, -0.02, -0.03, -0.09, -0.06, 0.06, -0.07, -0.00, -0.03, 0.00, -0.04, 0.01, -0.02, 0.08, 0.09, -0.04, 0.03, -0.06, -0.01, -0.01, 0.05, 0.00, -0.08, 0.00, 0.00, -0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.34, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.35, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, \n",
      "0.08, 0.08, 0.04, 0.03, -0.01, -0.08, -0.04, -0.01, -0.05, 0.07, 0.05, -0.00, -0.08, 0.04, -0.11, -0.02, -0.04, -0.04, -0.05, -0.00, -0.00, -0.07, 0.01, -0.10, 0.10, -0.00, 0.02, 0.09, 0.07, -0.02, -0.13, -0.02, 0.05, -0.04, -0.01, 0.06, 0.03, 0.07, 0.00, 0.05, 0.01, -0.04, -0.00, -0.05, 0.05, -0.03, -0.08, 0.05, 0.01, 0.02, 0.04, 0.03, 0.02, 0.02, 0.04, -0.01, -0.06, -0.04, 0.07, 0.10, -0.09, -0.03, -0.02, -0.08, 0.15, -0.04, -0.04, 0.04, -0.03, 0.02, 0.02, 0.04, -0.09, 0.08, 0.09, 0.01, -0.01, 0.05, 0.00, -0.02, -0.00, 0.05, 0.05, -0.07, -0.05, 0.05, 0.00, 0.01, 0.09, -0.01, -0.10, -0.10, 0.11, 0.00, -0.05, 0.02, -0.04, 0.02, -0.02, 0.01, 0.01, -0.05, -0.02, -0.06, 0.08, -0.05, -0.03, -0.06, -0.02, -0.03, -0.05, 0.01, -0.05, 0.00, 0.07, -0.05, -0.07, -0.04, -0.05, -0.02, -0.10, 0.09, -0.03, 0.09, 0.07, -0.04, -0.06, -0.02, 0.02, 0.05, -0.05, 0.06, 0.04, 0.00, 0.07, 0.00, -0.04, -0.01, -0.05, -0.07, -0.01, 0.08, -0.04, 0.07, 0.01, 0.03, 0.02, 0.09, -0.05, 0.04, -0.05, 0.05, -0.04, 0.02, -0.07, -0.03, 0.01, 0.04, -0.08, -0.01, -0.04, 0.02, -0.03, -0.08, 0.08, -0.09, -0.04, 0.11, 0.04, -0.03, -0.03, 0.04, 0.05, -0.03, -0.03, -0.00, 0.01, 0.07, 0.05, 0.01, -0.06, -0.05, 0.06, 0.01, -0.01, 0.02, 0.04, -0.00, 0.04, 0.02, -0.10, 0.03, 0.11, 0.00, 0.08, -0.04, -0.00, -0.06, -0.06, -0.05, 0.03, -0.02, 0.04, 0.09, 0.04, -0.02, 0.11, 0.03, 0.04, 0.09, 0.13, -0.04, -0.10, 0.03, -0.07, 0.06, -0.02, -0.00, 0.08, -0.06, -0.05, -0.04, 0.09, 0.08, -0.07, 0.00, -0.04, -0.05, 0.04, 0.06, -0.02, -0.04, -0.03, 0.08, 0.09, 0.02, -0.06, -0.05, -0.06, 0.00, -0.02, -0.08, 0.09, -0.10, 0.02, -0.07, -0.01, 0.08, -0.06, -0.10, -0.07, 0.03, -0.08, 0.04, -0.02, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.21, 0.00, 0.00, 0.01, 0.00, -0.02, 0.00, 0.00, -0.15, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.21, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.21, 0.08, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.09, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.15, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, -0.15, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, \n",
      "0.46821476423443054\n",
      "0.1456205150141733\n",
      "0.22172342720550553\n"
     ]
    }
   ],
   "source": [
    "[print(f\"{num:.2f}\", end=\", \") for num in res[0]]\n",
    "print()\n",
    "[print(f\"{num:.2f}\", end=\", \") for num in res[1]]\n",
    "print()\n",
    "[print(f\"{num:.2f}\", end=\", \") for num in res[-1]]\n",
    "type(res[0])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "arrays = [np.array(ls) for ls in res]\n",
    "\n",
    "print()\n",
    "print(np.dot(arrays[0], arrays[1]))\n",
    "print(np.dot(arrays[0], arrays[2]))\n",
    "print(np.dot(arrays[1], arrays[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\realj\\AppData\\Local\\Temp\\ipykernel_30464\\187219858.py:7: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  elastic_vector_store.client.delete_by_query(query={\n",
      "[INFO] [05-10 19:39:19] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [05-10 19:39:20] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    }
   ],
   "source": [
    "elastic_vector_store = ElasticsearchStore(\n",
    "    es_url=\"http://localhost:9200\",\n",
    "    index_name=\"rag_test\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "elastic_vector_store.client.delete_by_query(query={\n",
    "    \"match_all\": {}\n",
    "}, index=\"rag_test\", ignore=[400, 404],)\n",
    "\n",
    "elastic_vector_store = ElasticsearchStore.from_documents(\n",
    "    documents=titles,\n",
    "    embedding=embedding,\n",
    "    index_name=\"rag_test\",\n",
    "    es_url=\"http://localhost:9200\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-10 19:39:20] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "互联网+大学城闲散物流资源跨界整合创新实践\n",
      "高校校园建筑能耗模拟及节能改造设计---以广东白云学院为例\n",
      "“海上丝绸之路﹒中国史迹”申报世界文化遗产背景下台山山咀码头、三洲港及沿港临街环境整治设计\n",
      "大学毕业生面试服装设计与服饰搭配咨询服务工作室\n",
      "大学生对中西方传统节日价值取向的研究\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = elastic_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"大学生平台\")\n",
    "\n",
    "print(len(retrieved_docs))\n",
    "[print(doc.page_content) for doc in retrieved_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-10 19:39:21] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "刻纸艺术在室内陈设中的传承与创新\n",
      "高热导事故容错核燃料芯块的高温高压制备与研究\n",
      "多旋翼飞行器电网巡检相关问题的研究\n",
      "盆栽行业新型树屋的造景研发\n",
      "智能除臭马桶优化设计\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"创新研究啊\")\n",
    "\n",
    "print(len(retrieved_docs))\n",
    "[print(doc.page_content) for doc in retrieved_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [05-10 19:39:21] base.py:406 [t:6664]: retry is not available when stream is enabled\n",
      "[INFO] [05-10 19:39:21] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /chat/completions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，Jayden！很高兴认识你。请问有什么我可以帮助你的吗？或者我们可以聊聊你感兴趣的话题。', response_metadata={'token_usage': {}, 'model_name': 'ERNIE-3.5-8K', 'finish_reason': 'stop'}, id='run-2cb41953-2cba-473c-bb2f-e98a816f4b0a-0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain_core.language_models.chat_models import HumanMessage\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/chat/\n",
    "# https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint/\n",
    "\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-3.5-8K\", streaming=True)\n",
    "messages = [HumanMessage(content=\"你好，我是Jayden\")]\n",
    "llm.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"请根据学生情况和往年选题，为学生拟定几个合适的选题。\n",
    "学生情况：{student_info}\n",
    "拟定新的选题：\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-10 19:39:24] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请根据学生情况和往年选题，为学生拟定几个合适的选题。\n",
      "学生情况：信息管理与信息系统专业，自然语言处理方向\n",
      "拟定新的选题：\n"
     ]
    }
   ],
   "source": [
    "ex_stu_info = \"信息管理与信息系统专业，自然语言处理方向\"\n",
    "\n",
    "ex_msg = rag_prompt.invoke(\n",
    "    {\n",
    "        \"student_info\": ex_stu_info,\n",
    "        \"history_titles\": \";\".join([\n",
    "            doc.page_content for doc in\n",
    "            retriever.invoke(ex_stu_info, {\"k\": 5})\n",
    "        ])\n",
    "    }\n",
    ").to_messages()\n",
    "\n",
    "print(ex_msg[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \";\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"history_titles\": retriever | format_docs, \n",
    "        \"student_info\": RunnablePassthrough(),\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-10 19:39:24] openapi_requestor.py:336 [t:30924]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[WARNING] [05-10 19:39:24] base.py:406 [t:6664]: retry is not available when stream is enabled\n",
      "[INFO] [05-10 19:39:24] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /chat/completions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于学生为信息管理与信息系统专业背景，并专注于自然语言处理方向，且有过数学建模比赛的经历，以下是一些合适的选题建议：\n",
      "\n",
      "1. 基于自然语言处理的信息检索优化模型研究\n",
      "   选题理由：该选题结合了信息管理与自然语言处理的核心内容，通过数学建模优化信息检索效率，有助于学生利用数学建模技巧解决实际的信息管理问题。\n",
      "\n",
      "2. 基于深度学习的社交媒体情感分析模型研究\n",
      "   选题理由：社交媒体数据蕴含着丰富的情感信息，利用深度学习技术对其进行情感分析，有助于理解用户行为、优化信息推荐等。该选题既体现了自然语言处理的应用价值，也能锻炼学生的数学建模能力。\n",
      "\n",
      "3. 多源信息融合的自然语言处理模型研究\n",
      "   选题理由：在信息管理领域，多源信息融合是提高信息质量和利用率的重要手段。通过设计自然语言处理模型来实现多源信息的有效融合，有助于提升学生的信息整合和处理能力。\n",
      "\n",
      "4. 基于自然语言处理的个性化信息推荐系统研究\n",
      "   选题理由：在信息爆炸的时代，个性化信息推荐成为提高用户体验的关键。通过自然语言处理技术挖掘用户兴趣，结合数学建模优化推荐算法，可以构建出更加精准的个性化信息推荐系统。\n",
      "\n",
      "5. 基于文本挖掘的企业知识管理系统优化研究\n",
      "   选题理由：企业知识管理是企业核心竞争力的重要组成部分，通过文本挖掘技术提取和整理企业知识，结合数学建模优化知识管理流程，有助于提高企业的知识利用效率和管理水平。\n",
      "\n",
      "这些选题都紧密结合了信息管理与信息系统专业的核心知识点，同时突出了自然语言处理方向的应用特点，有助于学生在实践中提升数学建模和问题解决能力。"
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"信息管理与信息系统专业，自然语言处理方向，数学建模比赛经历\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_template = \"\"\"你是大学生创新创业指导中心的专业教授，请你根据学生情况和往年选题，为学生拟定几个合适的选题。\n",
    "学生情况：{student_info}\n",
    "往年选题：{history_titles}\n",
    "注意：严禁重复往年选题内容，**无需解释拟定选题的理由**，一行一个直接列出选题。\n",
    "拟定新的选题：\"\"\"\n",
    "\n",
    "new_rag_prompt = PromptTemplate.from_template(new_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-10 19:39:47] openapi_requestor.py:336 [t:26852]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[WARNING] [05-10 19:39:47] base.py:406 [t:6664]: retry is not available when stream is enabled\n",
      "[INFO] [05-10 19:39:47] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /chat/completions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 基于自然语言处理的智能医疗问答系统研究\n",
      "2. 信息管理与信息系统在智能物流中的应用探索\n",
      "3. 基于数据挖掘的电商平台用户行为分析与预测\n",
      "4. 信息管理与信息系统视角下的智慧城市构建策略\n",
      "5. 基于自然语言处理的在线教育平台学习效果评估系统研发\n",
      "6. 信息管理与信息系统对供应链管理效率提升的实践研究\n",
      "7. 面向智慧金融的自然语言处理技术在风险评估中的应用\n",
      "8. 基于信息管理与信息系统的公共卫生危机应对策略研究\n",
      "9. 自然语言处理在社交媒体情感分析中的应用与实践\n",
      "10. 基于数学建模的信息管理系统优化与决策支持研究"
     ]
    }
   ],
   "source": [
    "new_rag_chain = (\n",
    "    {\n",
    "        \"history_titles\": retriever | format_docs, \n",
    "        \"student_info\": RunnablePassthrough(),\n",
    "    }\n",
    "    | new_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "for chunk in new_rag_chain.stream(\"信息管理与信息系统专业，自然语言处理方向，数学建模比赛经历\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [05-10 19:39:56] openapi_requestor.py:336 [t:16080]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [05-10 19:39:56] base.py:406 [t:6664]: retry is not available when stream is enabled\n",
      "[INFO] [05-10 19:39:56] openapi_requestor.py:336 [t:6664]: requesting llm api endpoint: /chat/completions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 企业税务优化与财务决策支持系统研发\n",
      "2. 基于大数据的税务风险预警与应对策略研究\n",
      "3. 资本结构优化对企业价值的影响研究\n",
      "4. 税务筹划对企业现金流及财务绩效的影响分析\n",
      "5. 基于人工智能的税务审计与风险识别系统研究\n",
      "6. 企业税务合规性与可持续发展战略的关联研究\n",
      "7. 税务筹划对企业资本成本及投资决策的影响分析\n",
      "8. 跨国企业税务优化策略与国际税务合作研究\n",
      "9. 基于云计算的税务数据处理与可视化平台构建\n",
      "10. 企业税务筹划中的风险管理及应对策略研究"
     ]
    }
   ],
   "source": [
    "for chunk in new_rag_chain.stream(\"会计学专业，企业税务与决策项目经历，资本结构优化方向\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
